import DevTools_Stats_Utils as Utils
import pandas as pd
from scipy import stats
import numpy as np
import statsmodels.api as sm


df = pd.read_csv("data/cuped_info.csv")
df_ratio = pd.read_csv("data/找选接确完车主量.csv")


df.head(3)


df.columns


df.size





import numpy as np
import pandas as pd
from statsmodels.stats.power import TTestIndPower

data = df.copy()
control = data[data['group_name'] == '对照组']['ordercnt_after']
treatment = data[data['group_name'] == '实验组']['ordercnt_after']

# Calculate means
mean_control = np.mean(control)
mean_treatment = np.mean(treatment)

# Calculate standard deviations
std_control = np.std(control, ddof=1)  # ddof=1 for sample standard deviation
std_treatment = np.std(treatment, ddof=1)

# Calculate pooled standard deviation
n_control = len(control)
n_treatment = len(treatment)
pooled_std = np.sqrt(((n_control - 1) * std_control**2 + (n_treatment - 1) * std_treatment**2) / (n_control + n_treatment - 2))

# Calculate Cohen's d
cohens_d = (mean_treatment - mean_control) / pooled_std

# Print effect size
print(f"Cohen's d: {cohens_d:.2f}")

# Parameters for power analysis
alpha = 0.05  # significance level
powers = [0.70, 0.80, 0.90, 0.95, 0.99]

analysis = TTestIndPower()
# Calculate required sample sizes
sample_sizes = {power: analysis.solve_power(effect_size=cohens_d, power=power, alpha=alpha, ratio=1.0) for power in powers}
sample_sizes_df = pd.DataFrame(list(sample_sizes.items()), columns=['Power', 'Required Sample Size'])
print(sample_sizes_df)





from statsmodels.stats.power import NormalIndPower
from statsmodels.stats.proportion import proportion_effectsize

# Calculate the metric (proportion)
data = df_ratio.copy()
data['找完率'] = data['完单车主量'] / data['找单车主量']

# Extract proportions
p_control = data[data['group_name'] == '对照组']['找完率'].values[0]
p_experiment = data[data['group_name'] == '实验组']['找完率'].values[0]

# Print proportions
print(f"Control Group Proportion: {p_control:.2f}")
print(f"Experiment Group Proportion: {p_experiment:.2f}")

# Calculate Cohen's h (effect size for proportions)
effect_size = proportion_effectsize(p_experiment, p_control)

# Print effect size
print(f"Cohen's h: {effect_size:.2f}")

# Parameters for power analysis
alpha = 0.05  # significance level
powers = [0.70, 0.80, 0.90, 0.95, 0.99]

# Create an instance of the power analysis class
analysis = NormalIndPower()

# Calculate required sample sizes
sample_sizes = {power: analysis.solve_power(effect_size=effect_size, power=power, alpha=alpha, ratio=1.0) for power in powers}

# Convert results to a DataFrame for easy viewing
sample_sizes_df = pd.DataFrame(list(sample_sizes.items()), columns=['Power', 'Required Sample Size'])
print(sample_sizes_df)











# Filter data into experimental and control groups
experiment_group = df[df['group_name'] == '实验组']['gmv_after']
control_group = df[df['group_name'] == '对照组']['gmv_after']

# Perform Welch's T-test
t_stat, p_value = stats.ttest_ind(experiment_group, control_group, equal_var=True)

# Display the results
print(f"T-statistic: {t_stat}")
print(f"人均累积GMV: P-value: {p_value}")





# Filter data into experimental and control groups
experiment_group = df[df['group_name'] == '实验组']['ordercnt_after']
control_group = df[df['group_name'] == '对照组']['ordercnt_after']

# Perform Welch's T-test
t_stat, p_value = stats.ttest_ind(experiment_group, control_group, equal_var=True)

# Display the results
print(f"T-statistic: {t_stat}")
print(f"人均累积订单量: P-value: {p_value}")





proportion = 0.01
sampled_df = df.sample(frac=proportion, random_state=1)

experiment_group = sampled_df[sampled_df['group_name'] == '实验组']['ordercnt_after']
control_group = sampled_df[sampled_df['group_name'] == '对照组']['ordercnt_after']

# Welch's T-test
t_stat, p_value = stats.ttest_ind(experiment_group, control_group, equal_var=False)

print(f"T-statistic: {t_stat}")
print(f"样本不足：人均累积订单量: P-value: {p_value}")





import pandas as pd
from scipy import stats
import numpy as np
import statsmodels.api as sm

def bootstrap_ttest(data1, data2, n_bootstraps=10000):
    bootstrapped_means_diff = []
    for _ in range(n_bootstraps):
        sample1 = np.random.choice(data1, size=len(data1), replace=True)
        sample2 = np.random.choice(data2, size=len(data2), replace=True)
        bootstrapped_means_diff.append(sample1.mean() - sample2.mean())
    
    observed_diff = np.mean(data1) - np.mean(data2)
    p_value = np.mean(np.array(bootstrapped_means_diff) >= observed_diff)
    
    return observed_diff, p_value

def block_bootstrap_ttest(data1, data2, block_size, n_bootstraps=10000):
    def block_bootstrap_sample(data, block_size):
        n_blocks = np.int32(np.ceil(len(data) / block_size))
        blocks = [data[i * block_size:(i + 1) * block_size] for i in range(n_blocks)]
        bootstrap_sample = np.concatenate([blocks[np.random.randint(0, n_blocks)] for _ in range(n_blocks)])
        return bootstrap_sample[:len(data)]
    
    bootstrapped_means_diff = []
    for _ in range(n_bootstraps):
        sample1 = block_bootstrap_sample(data1, block_size)
        sample2 = block_bootstrap_sample(data2, block_size)
        bootstrapped_means_diff.append(sample1.mean() - sample2.mean())
    
    observed_diff = np.mean(data1) - np.mean(data2)
    p_value = np.mean(np.array(bootstrapped_means_diff) >= observed_diff)
    
    return observed_diff, p_value



# Check for dependency in the 'ordercnt_after' column
autocorrelation = sm.tsa.acf(sampled_df['ordercnt_after'], fft=False, nlags = np.round(np.sqrt(sampled_df.shape[0])))
# Check if there is significant autocorrelation 
dependency_present = np.any(np.abs(autocorrelation[1:]) > 0.3) 

if dependency_present:
    print("数据为不独立, 使用Block Bootstrap + T-test")
else:
    print("数据为独立, 使用Bootstrap + T-test")

if dependency_present:
    block_size = int(np.round(sampled_df.shape[0]/1000)) 
    observed_diff, p_value = block_bootstrap_ttest(experiment_group, control_group, block_size)
    print(f"Block Bootstrap t-test - Observed difference: {observed_diff}, P-value: {p_value}")
else:
    observed_diff, p_value = bootstrap_ttest(experiment_group, control_group)
    print(f"Bootstrap t-test - Observed difference: {observed_diff}, 样本不足：人均累积订单量 P-value: {p_value}")







import pandas as pd
import numpy as np
import statsmodels.api as sm
from scipy import stats

# Define the stratified bootstrap t-test function
def stratified_bootstrap_ttest(df, group_col, value_col, strata_cols, n_bootstraps=10000):
    strata = df.groupby(strata_cols)
    bootstrapped_means_diff = []

    for _ in range(n_bootstraps):
        bootstrapped_means = []

        for stratum_name, stratum_df in strata:
            experiment_group = stratum_df[stratum_df[group_col] == '实验组'][value_col].values
            control_group = stratum_df[stratum_df[group_col] == '对照组'][value_col].values

            if len(experiment_group) > 0 and len(control_group) > 0:
                sample1 = np.random.choice(experiment_group, size=len(experiment_group), replace=True)
                sample2 = np.random.choice(control_group, size=len(control_group), replace=True)
                bootstrapped_means.append(sample1.mean() - sample2.mean())

        if bootstrapped_means:
            bootstrapped_means_diff.append(np.mean(bootstrapped_means))

    observed_diff = df[df[group_col] == '实验组'][value_col].mean() - df[df[group_col] == '对照组'][value_col].mean()
    p_value = np.mean(np.array(bootstrapped_means_diff) >= observed_diff)
    
    return observed_diff, p_value

# Check for dependency in the 'ordercnt_after' column
nlag = int(np.sqrt(sampled_df.shape[0]))
autocorrelation = sm.tsa.acf(sampled_df['ordercnt_after'], fft=False, nlags=nlag)
dependency_threshold = 0.3
dependency_present = np.any(np.abs(autocorrelation[1:]) > dependency_threshold)

if dependency_present:
    print("数据为不独立, 使用Block Bootstrap + T-test")
else:
    print("数据为独立, 使用Bootstrap + T-test")

# Define columns for stratification
strata_cols = ['enter_date']  # Ensure this column exists in sampled_df

# Apply stratified bootstrap t-test
observed_diff, p_value = stratified_bootstrap_ttest(sampled_df, 'group_name', 'ordercnt_after', strata_cols)
print(f"Stratified Bootstrap t-test - Observed difference: {observed_diff}, 样本不足：人均累积订单量 P-value: {p_value}")









df_ratio['找选率'] = df_ratio['选单车主量'] / df_ratio['找单车主量']
df_ratio['选接率'] = df_ratio['接单车主量'] / df_ratio['选单车主量']
df_ratio['接确率'] = df_ratio['确认同行车主量'] / df_ratio['接单车主量']
df_ratio['接完率'] = df_ratio['完单车主量'] / df_ratio['接单车主量']
df_ratio['找完率'] = df_ratio['完单车主量'] / df_ratio['找单车主量']
df_ratio['确完率'] = df_ratio['完单车主量'] / df_ratio['确认同行车主量']
df_ratio.head()


df_ratio.columns


print(df_ratio)


metrics_data = { '找选率': ['找单车主量', '选单车主量'], 
                '选接率': ['选单车主量', '接单车主量'], 
                '接确率': ['接单车主量', '确认同行车主量'], 
                '接完率': ['接单车主量', '完单车主量'], 
                '找完率': ['找单车主量', '完单车主量'], 
                '确完率': ['确认同行车主量', '完单车主量'] }



# Define a function to perform the Chi-Square test
def chi_square_test(observed):
    chi2, p, _, _ = stats.chi2_contingency(observed)
    return chi2, p

# Perform the test for each metric
results = {}

for metric, counts in metrics_data.items():
    group_1 = df_ratio.loc[0, counts].values
    group_2 = df_ratio.loc[1, counts].values
    observed = [group_1, group_2]
    chi2, p = chi_square_test(observed)
    results[metric] = {'chi2': chi2, 'p-value': p}

results


from statsmodels.stats.proportion import proportions_ztest

# two-sample proportion test
def two_sample_proportion_test(success_a, size_a, success_b, size_b):
    count = np.array([success_a, success_b])
    nobs = np.array([size_a, size_b])
    stat, pval = proportions_ztest(count, nobs)
    return stat, pval

# Perform the test for each metric
results = {}

for metric, counts in metrics_data.items():
    success_a = df_ratio.loc[0, counts[1]]
    size_a = df_ratio.loc[0, counts[0]]
    success_b = df_ratio.loc[1, counts[1]]
    size_b = df_ratio.loc[1, counts[0]]
    
    stat, pval = two_sample_proportion_test(success_a, size_a, success_b, size_b)
    results[metric] = {'z-stat': stat, 'p-value': pval}

# Display the results
results


df.columns



